{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Step Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_step_forward\n",
    "from code_base.layer_utils import rel_error\n",
    "import numpy as np\n",
    "\n",
    "N, D, H = 3, 10, 4\n",
    "x = np.linspace(-0.4, 0.7, num=N*D).reshape(N, D)\n",
    "prev_h = np.linspace(-0.2, 0.5, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.1, 0.9, num=D*H).reshape(D, H)\n",
    "Wh = np.linspace(-0.3, 0.7, num=H*H).reshape(H, H)\n",
    "b = np.linspace(-0.2, 0.4, num=H)\n",
    "next_h, _ = rnn_step_forward(x, prev_h, Wx, Wh, b)\n",
    "expected_next_h = np.asarray([\n",
    "[-0.58172089, -0.50182032, -0.41232771, -0.31410098],\n",
    "[ 0.66854692, 0.79562378, 0.87755553, 0.92795967],\n",
    "[ 0.97934501, 0.99144213, 0.99646691, 0.99854353]])\n",
    "print('next_h error: ', rel_error(expected_next_h, next_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_step_forward\n",
    "import numpy as np\n",
    "\n",
    "x_shape = (3, 874)\n",
    "Wx_shape = (874, 128)\n",
    "h_shape = (3, 128)\n",
    "Wh_shape = (128, 128)\n",
    "b_shape = (128,)\n",
    "x = np.loadtxt('./input_files/x.csv', delimiter=',')\n",
    "x = x.reshape(x_shape)\n",
    "Wx = np.loadtxt('./input_files/Wx.csv', delimiter=',')\n",
    "Wx = Wx.reshape(Wx_shape)\n",
    "prev_h = np.loadtxt('./input_files/prev_h.csv', delimiter=',')\n",
    "prev_h = prev_h.reshape(h_shape)\n",
    "Wh = np.loadtxt('./input_files/Wh.csv', delimiter=',')\n",
    "Wh = Wh.reshape(Wh_shape)\n",
    "b = np.loadtxt('./input_files/b.csv', delimiter=',')\n",
    "out, _ = rnn_step_forward(x, prev_h, Wx, Wh, b)\n",
    "np.savetxt('./output_files/rnn_step_forward_out.csv', out.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Step Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_step_forward, rnn_step_backward\n",
    "from code_base.gradient_check import *\n",
    "from code_base.layer_utils import rel_error\n",
    "import numpy as np\n",
    "\n",
    "N, D, H = 4, 5, 6\n",
    "x = np.random.randn(N, D)\n",
    "h = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, H)\n",
    "Wh = np.random.randn(H, H)\n",
    "b = np.random.randn(H)\n",
    "out, cache = rnn_step_forward(x, h, Wx, Wh, b)\n",
    "dnext_h = np.random.randn(*out.shape)\n",
    "fx = lambda x: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fh = lambda prev_h: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "fb = lambda b: rnn_step_forward(x, h, Wx, Wh, b)[0]\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dnext_h)\n",
    "dprev_h_num = eval_numerical_gradient_array(fh, h, dnext_h)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dnext_h)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dnext_h)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dnext_h)\n",
    "dx, dprev_h, dWx, dWh, db = rnn_step_backward(dnext_h, cache)\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dprev_h error: ', rel_error(dprev_h_num, dprev_h))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_step_forward, rnn_step_backward\n",
    "import numpy as np\n",
    "\n",
    "x_shape = (3, 874)\n",
    "Wx_shape = (874, 128)\n",
    "h_shape = (3, 128)\n",
    "Wh_shape = (128, 128)\n",
    "b_shape = (128,)\n",
    "x = np.loadtxt('./input_files/x.csv', delimiter=',')\n",
    "x = x.reshape(x_shape)\n",
    "Wx = np.loadtxt('./input_files/Wx.csv', delimiter=',')\n",
    "Wx = Wx.reshape(Wx_shape)\n",
    "prev_h = np.loadtxt('./input_files/prev_h.csv', delimiter=',')\n",
    "prev_h = prev_h.reshape(h_shape)\n",
    "Wh = np.loadtxt('./input_files/Wh.csv', delimiter=',')\n",
    "Wh = Wh.reshape(Wh_shape)\n",
    "b = np.loadtxt('./input_files/b.csv', delimiter=',')\n",
    "out, cache = rnn_step_forward(x, prev_h, Wx, Wh, b)\n",
    "dhout = np.loadtxt('./input_files/dho.csv', delimiter=',')\n",
    "dx, dh, dWx, dWh, db = rnn_step_backward(dhout, cache)\n",
    "np.savetxt('./output_files/rnn_step_backward_out_dx.csv', dx.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_step_backward_out_dh.csv', dh.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_step_backward_out_dwx.csv', dWx.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_step_backward_out_dwh.csv', dWh.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_step_backward_out_db.csv', db.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_forward\n",
    "from code_base.layer_utils import *\n",
    "import numpy as np\n",
    "\n",
    "N, T, D, H = 2, 3, 4, 5\n",
    "x = np.linspace(-0.1, 0.3, num=N*T*D).reshape(N, T, D)\n",
    "h0 = np.linspace(-0.3, 0.1, num=N*H).reshape(N, H)\n",
    "Wx = np.linspace(-0.2, 0.4, num=D*H).reshape(D, H)\n",
    "Wh = np.linspace(-0.4, 0.1, num=H*H).reshape(H, H)\n",
    "b = np.linspace(-0.7, 0.1, num=H)\n",
    "h, _ = rnn_forward(x, h0, Wx, Wh, b)\n",
    "expected_h = np.asarray([\n",
    "[[-0.42070749, -0.27279261, -0.11074945, 0.05740409, 0.22236251],\n",
    "[-0.39525808, -0.22554661, -0.0409454, 0.14649412, 0.32397316],\n",
    "[-0.42305111, -0.24223728, -0.04287027, 0.15997045, 0.35014525],],\n",
    "[[-0.55857474, -0.39065825, -0.19198182, 0.02378408, 0.23735671],\n",
    "[-0.27150199, -0.07088804, 0.13562939, 0.33099728, 0.50158768],\n",
    "[-0.51014825, -0.30524429, -0.06755202, 0.17806392, 0.40333043]]])\n",
    "print('h error: ', rel_error(expected_h, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_forward\n",
    "import numpy as np\n",
    "\n",
    "x_all_shape = (3, 5, 874)\n",
    "Wx_shape = (874, 128)\n",
    "h_shape = (3, 128)\n",
    "Wh_shape = (128, 128)\n",
    "b_shape = (128,)\n",
    "x_all = np.loadtxt('./input_files/x_all.csv', delimiter=',')\n",
    "x_all = x_all.reshape(x_all_shape)\n",
    "Wx = np.loadtxt('./input_files/Wx.csv', delimiter=',')\n",
    "Wx = Wx.reshape(Wx_shape)\n",
    "h0 = np.loadtxt('./input_files/prev_h.csv', delimiter=',')\n",
    "h0 = prev_h.reshape(h_shape)\n",
    "Wh = np.loadtxt('./input_files/Wh.csv', delimiter=',')\n",
    "Wh = Wh.reshape(Wh_shape)\n",
    "b = np.loadtxt('./input_files/b.csv', delimiter=',')\n",
    "out, _ = rnn_forward(x_all, h0, Wx, Wh, b)\n",
    "np.savetxt('./output_files/rnn_forward_out.csv', out.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_forward, rnn_backward\n",
    "from code_base.gradient_check import *\n",
    "from code_base.layer_utils import *\n",
    "import numpy as np\n",
    "\n",
    "N, D, T, H = 2, 3, 10, 5\n",
    "x = np.random.randn(N, T, D)\n",
    "h0 = np.random.randn(N, H)\n",
    "Wx = np.random.randn(D, H)\n",
    "Wh = np.random.randn(H, H)\n",
    "b = np.random.randn(H)\n",
    "out, cache = rnn_forward(x, h0, Wx, Wh, b)\n",
    "dout = np.random.randn(*out.shape)\n",
    "dx, dh0, dWx, dWh, db = rnn_backward(dout, cache)\n",
    "fx = lambda x: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fh0 = lambda h0: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWx = lambda Wx: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fWh = lambda Wh: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "fb = lambda b: rnn_forward(x, h0, Wx, Wh, b)[0]\n",
    "dx_num = eval_numerical_gradient_array(fx, x, dout)\n",
    "dh0_num = eval_numerical_gradient_array(fh0, h0, dout)\n",
    "dWx_num = eval_numerical_gradient_array(fWx, Wx, dout)\n",
    "dWh_num = eval_numerical_gradient_array(fWh, Wh, dout)\n",
    "db_num = eval_numerical_gradient_array(fb, b, dout)\n",
    "print('dx error: ', rel_error(dx_num, dx))\n",
    "print('dh0 error: ', rel_error(dh0_num, dh0))\n",
    "print('dWx error: ', rel_error(dWx_num, dWx))\n",
    "print('dWh error: ', rel_error(dWh_num, dWh))\n",
    "print('db error: ', rel_error(db_num, db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import rnn_forward, rnn_backward\n",
    "import numpy as np\n",
    "\n",
    "x_all_shape = (3, 5, 874)\n",
    "Wx_shape = (874, 128)\n",
    "h_shape = (3, 128)\n",
    "Wh_shape = (128, 128)\n",
    "b_shape = (128,)\n",
    "dh_all_shape = (3, 5, 128)\n",
    "x_all = np.loadtxt('./input_files/x_all.csv', delimiter=',')\n",
    "x_all = x_all.reshape(x_all_shape)\n",
    "Wx = np.loadtxt('./input_files/Wx.csv', delimiter=',')\n",
    "Wx = Wx.reshape(Wx_shape)\n",
    "h0 = np.loadtxt('./input_files/prev_h.csv', delimiter=',')\n",
    "h0 = h0.reshape(h_shape)\n",
    "Wh = np.loadtxt('./input_files/Wh.csv', delimiter=',')\n",
    "Wh = Wh.reshape(Wh_shape)\n",
    "b = np.loadtxt('./input_files/b.csv', delimiter=',')\n",
    "out, cache = rnn_forward(x_all, h0, Wx, Wh, b)\n",
    "dhout = np.loadtxt('./input_files/dho_all.csv', delimiter=',')\n",
    "dhout = dhout.reshape(dh_all_shape)\n",
    "dx_all, dh0, dWx, dWh, db = rnn_backward(dhout, cache)\n",
    "np.savetxt('./output_files/rnn_backward_out_dx.csv', dx_all.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_backward_out_dh0.csv', dh0.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_backward_out_dwx.csv', dWx.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_backward_out_dwh.csv', dWh.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/rnn_backward_out_db.csv', db.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Temporal Bi-directional Concatenation Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import bidirectional_rnn_concatenate_forward\n",
    "from code_base.layer_utils import *\n",
    "import numpy as np\n",
    "\n",
    "N, T, H = 2, 4, 3\n",
    "h = np.linspace(-0.5, 0, num=N*T*H).reshape(N, T, H)\n",
    "hr = np.linspace(0, 0.5, num=N*T*H).reshape(N, T, H)\n",
    "mask = np.ones((N,T))\n",
    "mask[0][3] = 0 # length of s1 is 3\n",
    "mask[1][2] = mask[1][3] = 0 # length of s2 is 2\n",
    "ho, _ = bidirectional_rnn_concatenate_forward(h, hr, mask)\n",
    "expected_ho = np.array([[\n",
    "[-0.5, -0.47826087, -0.45652174, 0.13043478, 0.15217391, 0.17391304],\n",
    "[-0.43478261, -0.41304348, -0.39130435, 0.06521739, 0.08695652, 0.10869565],\n",
    "[-0.36956522, -0.34782609, -0.32608696, 0., 0.02173913, 0.04347826],\n",
    "[0., 0., 0., 0., 0., 0.]],\n",
    "[[-0.23913043, -0.2173913 , -0.19565217, 0.32608696, 0.34782609, 0.36956522],\n",
    "[-0.17391304, -0.15217391, -0.13043478, 0.26086957, 0.2826087, 0.30434783],\n",
    "[0., 0., 0., 0., 0., 0.],\n",
    "[0., 0., 0., 0., 0., 0.]]])\n",
    "print('ho error: ', rel_error(expected_ho, ho, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import bidirectional_rnn_concatenate_forward\n",
    "from code_base.gradient_check import *\n",
    "import numpy as np\n",
    "\n",
    "h_shape = (3, 5, 128)\n",
    "mask_shape = (3, 5)\n",
    "h = np.loadtxt('./input_files/h_all.csv', delimiter=',')\n",
    "h = h.reshape(h_shape)\n",
    "hr = np.loadtxt('./input_files/h_all_r.csv', delimiter=',')\n",
    "hr = hr.reshape(h_shape)\n",
    "mask = np.loadtxt('./input_files/mask.csv', delimiter=',')\n",
    "mask = mask.reshape(mask_shape)\n",
    "hout, _ = bidirectional_rnn_concatenate_forward(h, hr, mask)\n",
    "np.savetxt('./output_files/bidirectional_rnn_concatenate_forward_out.csv', hout.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Temporal Bi-directional Concatenation Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import bidirectional_rnn_concatenate_forward, bidirectional_rnn_concatenate_backward\n",
    "from code_base.layer_utils import *\n",
    "from code_base.gradient_check import *\n",
    "import numpy as np\n",
    "\n",
    "N, T, H = 2, 4, 3\n",
    "h = np.linspace(-0.5, 0, num=N*T*H).reshape(N, T, H)\n",
    "hr = np.linspace(0, 0.5, num=N*T*H).reshape(N, T, H)\n",
    "mask = np.ones((N,T))\n",
    "mask[0][3] = 0 # length of s1 is 3\n",
    "mask[1][2] = mask[1][3] = 0 # length of s2 is 2\n",
    "ho, cache = bidirectional_rnn_concatenate_forward(h, hr, mask)\n",
    "dho = np.linspace(0., 0.5, num=N*T*2*H).reshape(N, T, 2*H)\n",
    "dh, dhr = bidirectional_rnn_concatenate_backward(dho, cache)\n",
    "fh = lambda h: bidirectional_rnn_concatenate_forward(h, hr, mask)[0]\n",
    "fhr = lambda hr: bidirectional_rnn_concatenate_forward(h, hr, mask)[0]\n",
    "dh_num = eval_numerical_gradient_array(fh, h, dho)\n",
    "dhr_num = eval_numerical_gradient_array(fhr, hr, dho)\n",
    "print('dh error: ', rel_error(dh_num, dh, mask))\n",
    "print('dhr error: ', rel_error(dhr_num, dhr, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from code_base.rnn_layers import bidirectional_rnn_concatenate_forward, bidirectional_rnn_concatenate_backward\n",
    "import numpy as np\n",
    "\n",
    "h_shape = (3, 5, 128)\n",
    "mask_shape = (3, 5)\n",
    "h = np.loadtxt('./input_files/h_all.csv', delimiter=',')\n",
    "h = h.reshape(h_shape)\n",
    "hr = np.loadtxt('./input_files/h_all_r.csv', delimiter=',')\n",
    "hr = hr.reshape(h_shape)\n",
    "mask = np.loadtxt('./input_files/mask.csv', delimiter=',')\n",
    "mask = mask.reshape(mask_shape)\n",
    "hout, cache = bidirectional_rnn_concatenate_forward(h, hr, mask)\n",
    "dhout = np.loadtxt('./input_files/dhc_all.csv', delimiter=',')\n",
    "dhout = dhout.reshape(3, 5, 256)\n",
    "dh, dhr = bidirectional_rnn_concatenate_backward(dhout, cache)\n",
    "np.savetxt('./output_files/bidirectional_rnn_concatenate_backward_out_h.csv', dh.ravel(), delimiter=',')\n",
    "np.savetxt('./output_files/bidirectional_rnn_concatenate_backward_out_hr.csv', dhr.ravel(), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for Sentiment Analysis - Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code_base.classifiers.rnn import *\n",
    "# If you do brnn, please import from code_base.classifiers.brnn instead\n",
    "import numpy as np\n",
    "\n",
    "N, H, A, O = 2, 6, 5, 2\n",
    "word_to_idx = { 'awesome': 0, 'reading':1, 'pretty': 2, 'dog': 3, 'movie': 4,\n",
    "                'liked': 5, 'most': 6, 'admired': 7, 'bad': 8, 'fucking': 9}\n",
    "V = len(word_to_idx)\n",
    "T = 4\n",
    "model = SentimentAnalysisRNN(word_to_idx,\n",
    "    hidden_dim=H,\n",
    "    fc_dim=A,\n",
    "    output_dim=O,\n",
    "    cell_type='rnn',\n",
    "    dtype=np.float64)\n",
    "# Set all model parameters to fixed values\n",
    "for k, v in model.params.items():\n",
    "    model.params[k] = np.linspace(-1.4, 1.3, num=v.size).reshape(*v.shape)\n",
    "labels = np.array([1, 0], dtype=np.int32)\n",
    "wordvecs = np.zeros((N, T, V))\n",
    "wordvecs[0, 0, 0] = wordvecs[0, 1, 5] = wordvecs[0, 2, 2] = wordvecs[0, 3, 7] = 1\n",
    "wordvecs[1, 0, 4] = wordvecs[1, 1, 8] = wordvecs[1, 2, 5] = 1\n",
    "mask = np.ones((N, T))\n",
    "mask[1, 3] = 0\n",
    "loss, grads = model.loss(wordvecs, labels, mask)\n",
    "expected_loss = 2.99619226823\n",
    "# For brnn, the expected_loss should be 2.9577205234\n",
    "print('loss: ', loss)\n",
    "print('expected loss: ', expected_loss)\n",
    "print('difference: ', abs(loss - expected_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN for Sentiment Analysis - Backward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from code_base.classifiers.rnn import *\n",
    "# If you do brnn, please import from code_base.classifiers.brnn instead\n",
    "from code_base.gradient_check import *\n",
    "from code_base.layer_utils import rel_error\n",
    "import numpy as np\n",
    "\n",
    "N, T, H, A, O = 2, 4, 6, 5, 2\n",
    "word_to_idx = {'awesome': 0, 'reading':1, 'pretty': 2, 'dog': 3, 'movie': 4,\n",
    "                'liked': 5, 'most': 6, 'admired': 7, 'bad': 8, 'fucking': 9}\n",
    "V = len(word_to_idx)\n",
    "labels = np.array([1, 0], dtype=np.int32)\n",
    "wordvecs = np.zeros((N, T, V))\n",
    "wordvecs[0, 0, 0] = wordvecs[0, 1, 5] = wordvecs[0, 2, 2] = wordvecs[0, 3, 7] = 1\n",
    "wordvecs[1, 0, 4] = wordvecs[1, 1, 8] = wordvecs[1, 2, 5] = 1\n",
    "mask = np.ones((N, T))\n",
    "mask[1, 3] = 0\n",
    "model = SentimentAnalysisRNN(word_to_idx,\n",
    "    hidden_dim=H,\n",
    "    fc_dim=A,\n",
    "    output_dim=O,\n",
    "    cell_type='rnn',\n",
    "    dtype=np.float64,\n",
    ")\n",
    "loss, grads = model.loss(wordvecs, labels, mask)\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(wordvecs, labels, mask)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name],\n",
    "verbose=False, h=1e-6)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print('%s relative error: %e' % (param_name, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Inference on Small Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from code_base.sentiment_analysis_solver import *\n",
    "from code_base.classifiers.rnn import *\n",
    "# If you do brnn, please import from code_base.classifiers.brnn instead\n",
    "from code_base.data_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "download_corpus()\n",
    "small_data = load_data('code_base/datasets/train.csv', sample=True)\n",
    "small_rnn_model = SentimentAnalysisRNN(\n",
    "    cell_type='rnn',\n",
    "    word_to_idx=load_dictionary('code_base/datasets/dictionary.csv')\n",
    ")\n",
    "small_rnn_solver = SentimentAnalysisSolver(small_rnn_model,\n",
    "    small_data,\n",
    "    update_rule='sgd',\n",
    "    num_epochs=100,\n",
    "    batch_size=100,\n",
    "    optim_config={\n",
    "        'learning_rate': 5e-3,\n",
    "    },\n",
    "    lr_decay=1.0,\n",
    "    verbose=True,\n",
    "    print_every=10,\n",
    ")\n",
    "small_rnn_solver.train()\n",
    "\n",
    "# we will use the same batch of training data for inference\n",
    "# this is just to let you know the procedure of inference\n",
    "preds = small_rnn_solver.test(split='train')\n",
    "np.savetxt('./output_files/rnn_prediction_prob.csv', preds.ravel(), delimiter=',')\n",
    "# If you do brnn, please save result to ./output_files/brnn_prediction_prob.csv\n",
    "\n",
    "# Plot the training losses\n",
    "plt.plot(small_rnn_solver.loss_history)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
